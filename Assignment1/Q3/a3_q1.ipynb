{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Q3: Real World Dataset</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import autograd.numpy as np  # when testing gradient\n",
    "from cvxopt import matrix, solvers\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "\n",
    "print(\"Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##imports from q1\n",
    "\n",
    "\n",
    "def l2_Loss(w, X,y):\n",
    "\n",
    "    predicted_diff = (np.linalg.norm(X @ w - y)**2)\n",
    "    relative_result = predicted_diff / (2*X.shape[0])\n",
    "    return relative_result\n",
    "\n",
    "\n",
    "def l1_Loss(w, X,y):\n",
    "    predicted = np.abs(X@w - y)\n",
    "    avg = np.mean(predicted)\n",
    "    return avg\n",
    "\n",
    "def lInf_Loss(w, X,y):\n",
    "    diff = np.abs(X@w-y)\n",
    "    max_val = np.amax(diff)\n",
    "    return max_val\n",
    "\n",
    "\n",
    "def compute_loss(w_l2, w_l1,w_Linf,X,y):\n",
    "    results = np.zeros([3, 3])\n",
    "\n",
    "    results[0,0] = l2_Loss(w_l2, X,y)\n",
    "    results[1,0] = l2_Loss(w_l1,X,y)\n",
    "    results[2,0] = l2_Loss(w_Linf, X, y)\n",
    "    \n",
    "    results[0,1] = l1_Loss(w_l2, X,y)\n",
    "    results[1,1] = l1_Loss(w_l1,X,y)\n",
    "    results[2,1] = l1_Loss(w_Linf, X, y)\n",
    "\n",
    "    results[0,2] = lInf_Loss(w_l2, X,y)\n",
    "    results[1,2] = lInf_Loss(w_l1,X,y)\n",
    "    results[2,2] = lInf_Loss(w_Linf, X, y)\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q2  imports\n",
    "\n",
    "#Q2c\n",
    "\n",
    "def sigmoid(x):\n",
    "    return np.exp(-np.logaddexp(0, -x))\n",
    "\n",
    "\n",
    "def logisticRegObj(w, X, y):\n",
    "    pred = X @ w\n",
    "    n = X.shape[0]\n",
    "    \n",
    "    objval = (1/n) * np.sum(np.logaddexp(0, -pred) - y * pred)\n",
    "    grad = (1/n) * X.T @ (sigmoid(pred) - y)\n",
    "    \n",
    "    return objval, grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3a)\n",
    "\n",
    "def preprocessAutoMPG(dataset_folder):\n",
    "\n",
    "    data_df = pd.read_csv(os.path.join(dataset_folder, \"auto-mpg.data\"), \n",
    "                          header=None, \n",
    "                          delim_whitespace=True)\n",
    "    \n",
    "    print(data_df.head())\n",
    "\n",
    "\n",
    "    del data_df[8]    #car name\n",
    "    del data_df[7]  #origin\n",
    "\n",
    "    df_data = data_df.dropna() #drop rows with any missing data\n",
    "\n",
    "    labels = df_data[0].to_numpy(float)[:, None]\n",
    "    del df_data[0]\n",
    "\n",
    "    matrix = df_data.to_numpy(float)\n",
    "\n",
    "    return matrix, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gd(func, w_init, X, y, step_size, max_iter, tol=1e-10):\n",
    "\n",
    "    w = w_init\n",
    "\n",
    "    for i in range(max_iter):\n",
    "        objval, gradient = func(w,X,y)\n",
    "        \n",
    "        norm = np.linalg.norm(gradient)\n",
    "        if norm < tol: #stop when gradient is good enough\n",
    "            break\n",
    "\n",
    "        w = w - step_size * gradient\n",
    "\n",
    "    return 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3b\n",
    "\n",
    "def runAutoMPG(dataset_folder):\n",
    "\n",
    "    X, y = preprocessAutoMPG(dataset_folder)\n",
    "    n, d = X.shape\n",
    "    X = np.concatenate((np.ones((n, 1)), X), axis=1) # augment\n",
    "    n_runs = 100\n",
    "    train_loss = np.zeros([n_runs, 3, 3]) # n_runs * n_models * n_metrics\n",
    "    test_loss = np.zeros([n_runs, 3, 3]) # n_runs * n_models * n_metrics\n",
    "    \n",
    "    for r in range(n_runs):\n",
    "        \n",
    "        #partition data\n",
    "        rand_indices = np.random.permutation(n)\n",
    "        num_training = n // 2\n",
    "        train_indices = rand_indices[:num_training]\n",
    "        test_indices = rand_indices[num_training:]\n",
    "\n",
    "        X_train, y_train = X[train_indices], y[train_indices]\n",
    "        X_test, y_test = X[test_indices], y[test_indices]\n",
    "\n",
    "        l1model = l1_Loss(X_train,y_train)\n",
    "        l2model = l2_loss(X_train,y_train)\n",
    "        linfmodel = linfloss(X_train,y_train)\n",
    "\n",
    "        train_loss = compute_loss(l2model,l1model,linfmodel,X_train,y_train)\n",
    "        test_loss = compute_loss(l2model,l1model,linfmodel,X_test,y_test)\n",
    "\n",
    "        avg_train_losses = np.mean(train_loss, axis=0)\n",
    "        avg_test_losses = np.mean(test_loss, axis=0)\n",
    "\n",
    "\n",
    "        return avg_train_losses, avg_test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "       18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
      "       36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53,\n",
      "       54, 55, 56, 57, 58, 59, 60],\n",
      "      dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "#Q3c\n",
    "\n",
    "def preprocessSonar(dataset_folder):\n",
    "\n",
    "    data_df = pd.read_csv(os.path.join(dataset_folder, \"sonar.all-data\"), \n",
    "                          header=None, \n",
    "                          delim_whitespace=True)\n",
    "\n",
    "\n",
    "    # Convert labels\n",
    "    data_df[60] = (data_df[60] == 'R').astype(float)\n",
    "    y = data_df[60].to_numpy()[:, None]\n",
    "    \n",
    "    #remove labels from the data\n",
    "    del data_df[60]\n",
    "    X = data_df.to_numpy()\n",
    "\n",
    "    return X, y\n",
    "\n",
    "sonar_datapath = \"/Users/mariopardo/OnThisMac/Programming/C3105_Group62/Assignment1/Data/connectionist+bench+sonar+mines+vs+rocks\"\n",
    "\n",
    "preprocessSonar(sonar_datapath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#q3d\n",
    "\n",
    "def runSonar(dataset_folder):\n",
    "\n",
    "    X, y = preprocessSonar(dataset_folder)\n",
    "    n, d = X.shape\n",
    "    X = np.concatenate((np.ones((n, 1)), X), axis=1) # augment\n",
    "    eta_list = [0.1, 1, 10, 100]\n",
    "\n",
    "    train_acc = np.zeros([len(eta_list)])\n",
    "    val_acc = np.zeros([len(eta_list)])\n",
    "    test_acc = np.zeros([len(eta_list)])\n",
    "\n",
    "    indices = np.random.permutation(n)\n",
    "    train_size = round(n * 0.4)\n",
    "    val_size = round(n * 0.4)\n",
    "    \n",
    "    train_indices = indices[:train_size]\n",
    "    val_indices = indices[train_size:train_size + val_size]\n",
    "    test_indices = indices[train_size + val_size:]\n",
    "\n",
    "    Xtrain, ytrain = X[train_indices], y[train_indices]\n",
    "    Xval, yval = X[val_indices], y[val_indices]\n",
    "    Xtest, ytest = X[test_indices], y[test_indices]\n",
    "\n",
    "\n",
    "    for i, eta in enumerate(eta_list):\n",
    "        w_init = np.zeros([d + 1, 1])\n",
    "        w = gd(logisticRegObj, w_init, Xtrain, ytrain, eta, max_iter=1000, tol=1e-8)\n",
    "\n",
    "        # TODO: Evaluate the model's accuracy on the training\n",
    "        # data. Save it to `train_acc`\n",
    "        train_pred = (1/2) * (1 * np.sign(Xtrain @ w))\n",
    "        train_acc[i] = np.sum(ytrain == train_pred) / Xtrain.shape[0]\n",
    "\n",
    "        # TODO: Evaluate the model's accuracy on the validation\n",
    "            #       data. Save it to `val_acc`\n",
    "        val_pred = 0.5 * (1 + np.sign(Xval @ w))\n",
    "        val_acc[i] = np.sum(yval == val_pred) / Xval.shape[0]\n",
    "\n",
    "            \n",
    "        test_pred = 0.5 * (1 + np.sign(Xtest @ w))\n",
    "        test_acc[i] = np.sum(ytest == test_pred) / Xtest.shape[0]\n",
    "\n",
    "    return train_acc, val_acc, test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
